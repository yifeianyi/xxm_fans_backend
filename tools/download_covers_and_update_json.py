#!/usr/bin/env python
"""
ä¸‹è½½happy_data_list.jsonä¸­çš„å°é¢å›¾ç‰‡å¹¶æ›´æ–°JSONæ–‡ä»¶
å°†å°é¢è·¯å¾„ä»Bç«™é“¾æ¥æ”¹ä¸ºæœ¬åœ°è·¯å¾„æ ¼å¼ï¼šcovers/year/month/year-month-day.jpg
"""

import json
import os
import requests
from datetime import datetime
import time
from urllib.parse import urlparse
import hashlib

def download_image(url, save_path):
    """ä¸‹è½½å›¾ç‰‡åˆ°æŒ‡å®šè·¯å¾„"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        with open(save_path, 'wb') as f:
            f.write(response.content)
        
        return True
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥ {url}: {e}")
        return False

def get_filename_from_url(url):
    """ä»URLä¸­æå–æ–‡ä»¶å"""
    parsed = urlparse(url)
    return os.path.basename(parsed.path)

def process_json_file(json_file_path, output_dir):
    """å¤„ç†JSONæ–‡ä»¶ï¼Œä¸‹è½½å›¾ç‰‡å¹¶æ›´æ–°è·¯å¾„"""
    
    # è¯»å–JSONæ–‡ä»¶
    print(f"ğŸ“– è¯»å–JSONæ–‡ä»¶: {json_file_path}")
    with open(json_file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"ğŸ“Š æ€»å…± {len(data)} æ¡è®°å½•")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_items = len(data)
    downloaded_count = 0
    updated_count = 0
    failed_count = 0
    
    # ç”¨äºå»é‡çš„å­—å…¸ï¼Œé¿å…é‡å¤ä¸‹è½½ç›¸åŒå›¾ç‰‡
    downloaded_images = {}
    
    for i, item in enumerate(data):
        if i % 100 == 0:
            print(f"â³ å¤„ç†è¿›åº¦: {i}/{total_items}")
        
        # è·å–æ—¶é—´ä¿¡æ¯
        time_str = item.get('æ—¶é—´', '')
        if not time_str:
            print(f"âš ï¸  ç¬¬ {i+1} æ¡è®°å½•ç¼ºå°‘æ—¶é—´ä¿¡æ¯ï¼Œè·³è¿‡")
            failed_count += 1
            continue
        
        try:
            # è§£ææ—¶é—´
            date_obj = datetime.strptime(time_str, '%Y-%m-%d')
            year = date_obj.year
            month = date_obj.month
            day = date_obj.day
            
            # æ„å»ºæ–°çš„å°é¢è·¯å¾„
            new_cover_path = f"covers/{year:04d}/{month:02d}/{year:04d}-{month:02d}-{day:02d}.jpg"
            
            # è·å–åŸå§‹å°é¢URL
            original_cover_url = item.get('å°é¢', '')
            if not original_cover_url:
                print(f"âš ï¸  ç¬¬ {i+1} æ¡è®°å½•ç¼ºå°‘å°é¢URLï¼Œè·³è¿‡")
                failed_count += 1
                continue
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»ä¸‹è½½è¿‡ç›¸åŒçš„å›¾ç‰‡
            if original_cover_url in downloaded_images:
                # ä½¿ç”¨å·²ä¸‹è½½çš„å›¾ç‰‡è·¯å¾„
                item['å°é¢'] = downloaded_images[original_cover_url]
                updated_count += 1
                continue
            
            # æ„å»ºä¿å­˜è·¯å¾„
            save_path = os.path.join(output_dir, new_cover_path)
            
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½
            if os.path.exists(save_path):
                print(f"âœ… æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {new_cover_path}")
                downloaded_images[original_cover_url] = new_cover_path
                item['å°é¢'] = new_cover_path
                updated_count += 1
                continue
            
            # ä¸‹è½½å›¾ç‰‡
            print(f"ğŸ“¥ ä¸‹è½½å›¾ç‰‡: {original_cover_url} -> {new_cover_path}")
            if download_image(original_cover_url, save_path):
                downloaded_count += 1
                downloaded_images[original_cover_url] = new_cover_path
                item['å°é¢'] = new_cover_path
                updated_count += 1
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(0.1)
            else:
                failed_count += 1
                
        except Exception as e:
            print(f"âŒ å¤„ç†ç¬¬ {i+1} æ¡è®°å½•æ—¶å‡ºé”™: {e}")
            failed_count += 1
    
    # ä¿å­˜æ›´æ–°åçš„JSONæ–‡ä»¶
    output_json_path = json_file_path.replace('.json', '_updated.json')
    print(f"ğŸ’¾ ä¿å­˜æ›´æ–°åçš„JSONæ–‡ä»¶: {output_json_path}")
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“ˆ å¤„ç†å®Œæˆ!")
    print(f"âœ… æˆåŠŸä¸‹è½½: {downloaded_count} å¼ å›¾ç‰‡")
    print(f"âœ… æˆåŠŸæ›´æ–°: {updated_count} æ¡è®°å½•")
    print(f"âŒ å¤±è´¥: {failed_count} æ¡è®°å½•")
    print(f"ğŸ“ å›¾ç‰‡ä¿å­˜ç›®å½•: {output_dir}")
    print(f"ğŸ“„ æ›´æ–°åçš„JSONæ–‡ä»¶: {output_json_path}")

def main():
    # é…ç½®è·¯å¾„
    json_file_path = 'happy_data_list.json'
    output_dir = 'xxm_fans_frontend/public'
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(json_file_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {json_file_path}")
        return
    
    # æ£€æŸ¥è¾“å‡ºç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(output_dir):
        print(f"âŒ æ‰¾ä¸åˆ°è¾“å‡ºç›®å½•: {output_dir}")
        return
    
    print("ğŸš€ å¼€å§‹å¤„ç†å°é¢å›¾ç‰‡ä¸‹è½½å’ŒJSONæ›´æ–°...")
    process_json_file(json_file_path, output_dir)

if __name__ == '__main__':
    main() 